{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B Testing to Determine an effective intervention to decrease early Udacity course cancellation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as mt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Udacity's A/B testing course\n",
    "\n",
    "Udacity published a great free course for A/B Testing, also known as split tests, which are online experiments used to test potential improvements to a website or mobile app. This Python notebook is a walkthrough solution of the final project.\n",
    "\n",
    "Udacity's A/B Testing course is presented by Google and focuses on design and analysis of A/B tests. \n",
    "\n",
    "The course covers how to choose and characterize metrics to evaluate your experiments, how to design an experiment with enough statistical power and how to analyze the results and draw valid conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment overview "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Name: \"Free Trial\" Screener.\n",
    "\n",
    "It is conducted by Udacity, with the overall business goal of maximizing course completion by students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Current conditions before change \n",
    "At the time of this experiment, Udacity courses currently have two options on the course overview page: \"start free trial\", and \"access course materials\".\n",
    "If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first.\n",
    "If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Description of experimented change \n",
    "In the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course.\n",
    "If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free.\n",
    "\n",
    "At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Experiment hypothesis \n",
    "The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough time—without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Experiment details \n",
    "The unit of diversion is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. \n",
    "\n",
    "The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metric choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two types of metrics for a successful experiment (or at least, a safe one); Invariate and evaluation metrics. \n",
    "\n",
    "Invariate metrics are used for \"sanity checks\", that is, to make sure our experiment (the way we presented a change to a part of the population, as well as the way we collected the data) is not inherently wrong. Basically, this means we pick metrics which we consider not to change (not to be affected) because of our experiment and later make sure these metrics don't change drastically between our control and experiment groups.\n",
    "\n",
    "Evaluation metrics on the other hand, are the metrics in which we expect to see a change, and are relevant to the business goals we aim to achieve. For each metric we state a  Dmin  - which marks the minimum change which is practically significant to the business. For instance, stating that any increase in retention that is under 2%, even if statistically significant, is not practical to the business.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Invariate metrics - sanity checks\n",
    "\n",
    "Dmin of each metric\n",
    "\n",
    "- Number of Cookies in Course Overview Page (unique daily cookies on page - Ck): 3000 cookies \n",
    "- Number of Clicks on Free Trial Button (unique daily cookies who clicked - Cl): 240 clicks\n",
    "- Free Trial button Click-Through-Probability (Cl/Ck): 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Evaluation metrics - performance indicators\n",
    "\n",
    "Dmin of each metric\n",
    "\n",
    "- Gross Conversion (enrolled / Cl): 0.01\n",
    "- Retention (paid / enrolled): 0.01\n",
    "- Net Conversion (paid / Cl): 0.0075\t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Baseline values of metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Udacity gives the following rough estimates for these metrics (presumably collected from aggregates on daily traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place estimators into a dictionary for ease of use later\n",
    "baseline = {\"Cookies\":40000,\"Clicks\":3200,\"Enrollments\":660,\"CTP\":0.08,\"GConversion\":0.20625,\n",
    "           \"Retention\":0.53,\"NConversion\":0.109313}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Estimating standard deviation \n",
    "Once we collected these estimates, we should estimate the standard deviation of a metric, this is computed for sample size calculations and confidence intervals for our results. The more variant a metric is, the harder it is to reach a significant result. Assuming a sample size of 5,000 cookies visiting the course overview page per day (as given in project's instructions) - we want to estimate a standard deviation, for the evaluation metrics only. The sample size we are considering should be smaller than the \"population\" we collected and small enough to have two groups with that size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Scaling collected data \n",
    "For all the calculations to follow we need to scale our collected counts estimates of metrics with the sample size we specified for variance estimation. In this case, from 40000 unique cookies to visit the course overview page per day, to 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cookies': 5000,\n",
       " 'Clicks': 400.0,\n",
       " 'Enrollments': 82.5,\n",
       " 'CTP': 0.08,\n",
       " 'GConversion': 0.20625,\n",
       " 'Retention': 0.53,\n",
       " 'NConversion': 0.109313}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale The counts estimates\n",
    "baseline[\"Cookies\"] = 5000\n",
    "baseline[\"Clicks\"] = baseline[\"Clicks\"]*(5000/40000)\n",
    "baseline[\"Enrollments\"] = baseline[\"Enrollments\"]*(5000/40000)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Estimating analytically "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to estimate variance analytically, we can assume metrics which are probabilities (p̂) are binomially distributed.\n",
    "\n",
    "This assumption is only valid when the unit of diversion of the experiment is equal to the unit of analysis (the denominator of the metric formula).\n",
    "\n",
    "In the cases when this is not valid, the actual variance might be different and it is recommended to estimate it empirically.\n",
    "For each metric, we need to plug two variables into the formula:\n",
    "p̂ - baseline probability of the event to occur\n",
    "n - sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GConversion standard deviation: 0.0202\n",
      "NConversion standard deviation: 0.0156\n"
     ]
    }
   ],
   "source": [
    "# Correspond the dmin and denominator given in 3.1 to the conversion rate\n",
    "conversion_dict = {\n",
    "    'GConversion':[0.01,'Clicks'], # The first corresponds to d_min, the second corresponds to the denominator\n",
    "    'NConversion':[0.0075,'Clicks']\n",
    "}\n",
    "\n",
    "def cal_sd(conversion,d_min,denominator):\n",
    "    '''\n",
    "    Conversion\n",
    "    d_min \n",
    "    denominator (denominator of conversion rate)\n",
    "    '''\n",
    "    R = {}\n",
    "    R['d_min'] = d_min \n",
    "    R['p'] = baseline[conversion]\n",
    "    R['n'] = baseline[denominator]\n",
    "    R['sd'] = round(mt.sqrt((R[\"p\"]*(1-R[\"p\"]))/R[\"n\"]),4)\n",
    "    print('{} standard deviation:'.format(conversion),R['sd'])\n",
    "\n",
    "conversions = ['GConversion','NConversion']\n",
    "for conversion in conversions:\n",
    "    d_min = conversion_dict[conversion][0]\n",
    "    denominator = conversion_dict[conversion][1]\n",
    "    cal_sd(conversion,d_min,denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Experiment sizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given  α = 0.05  (significance level) and  β = 0.2  (power), we want to estimate how many total pageviews (cookies who viewed the course overview page) we need in the experiment. This amount will be divided into the two groups: control and experiment. This calculation can be done using an online calculator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Get z-score critical value and standard deviations \n",
    "\n",
    "We can use python's scipy.stats.norm package to get all the required methods for normal distribution. \n",
    "\n",
    "The ppf method gives us access to the Percent Point Function (ppf) or Quantile Function, and besides it being the inverse of the Cummulative Distribution Function (cdf), this is the functions that will give back our required critical z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caculate sd1 and sd2\n",
    "def get_sds(p,d):\n",
    "    sd1 = mt.sqrt(2*p*(1-p))\n",
    "    sd2 = mt.sqrt(p*(1-p)+(p+d)*(1-(p+d)))\n",
    "    x = [sd1,sd2]\n",
    "    return x\n",
    "\n",
    "# Caculate z-score\n",
    "def get_z_score(alpha):\n",
    "    return norm.ppf(alpha)\n",
    "\n",
    "# Caculate sample size\n",
    "def get_sampSize(sds,alpha,beta,d):\n",
    "    n=pow((get_z_score(1-alpha/2)*sds[0]+get_z_score(1-beta)*sds[1]),2)/pow(d,2)\n",
    "    return n\n",
    "\n",
    "# Specify the baseline data p and d\n",
    "GC = {}\n",
    "GC[\"p\"] = baseline[\"GConversion\"]\n",
    "GC[\"d\"] = 0.01\n",
    "NC = {}\n",
    "NC[\"p\"] = baseline[\"NConversion\"]\n",
    "NC[\"d\"] = 0.0075"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Calculate sample size per metric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gross conversion: enrolled / clicks (\"free trial button\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645875.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC[\"SampSize\"] = round(get_sampSize(get_sds(GC[\"p\"],GC[\"d\"]), 0.05, 0.2, GC[\"d\"]))\n",
    "GC[\"SampSize\"] = round(GC[\"SampSize\"]/0.08*2)\n",
    "GC[\"SampSize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net conversion: paid / clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685325.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NC[\"SampSize\"] = round(get_sampSize(get_sds(NC[\"p\"],NC[\"d\"]),0.05,0.2,NC[\"d\"]))\n",
    "NC[\"SampSize\"] = NC[\"SampSize\"] / 0.08*2\n",
    "NC[\"SampSize\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. A/B testing experiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Pageviews</th>\n",
       "      <th>Clicks</th>\n",
       "      <th>Enrollments</th>\n",
       "      <th>Payments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Pageviews  Clicks  Enrollments  Payments\n",
       "0  Sat, Oct 11       7723     687        134.0      70.0\n",
       "1  Sun, Oct 12       9102     779        147.0      70.0\n",
       "2  Mon, Oct 13      10511     909        167.0      95.0\n",
       "3  Tue, Oct 14       9871     836        156.0     105.0\n",
       "4  Wed, Oct 15      10014     837        163.0      64.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control = pd.read_csv(\"/Users/miaaa/ab-testing/control_data.csv\")\n",
    "experiment = pd.read_csv(\"/Users/miaaa/ab-testing/experiment_data.csv\")\n",
    "control.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing we have to do before even beginning to analyze this experiment's results is sanity checks. \n",
    "\n",
    "These checks help verify that the experiment was conducted as expected and that other factors did not influence the data which we collected.\n",
    "\n",
    "This also makes sure that data collection was correct.\n",
    "\n",
    "We have 3 Invariant metrics::\n",
    "\n",
    "- Number of cookies in course overview page\n",
    "- Number of clicks on free trial button\n",
    "- Free trial button click-through-probability\n",
    "\n",
    "Two of these metrics are simple counts like number of cookies or number of clicks and the third is a probability (CTP). We will use two different ways of checking whether these obsereved values are like we expect (if in fact the experiment was not damaged.\n",
    "\n",
    "Sanity checks for differences between counts \n",
    "Number of cookies who viewed the course overview page - Starting from this simpel invariant metric, we want to count the total amount of cookie pageviews we diverted to each group and see if there is a significant difference int he amount of cookies. A significant difference will imply a biased experiment that we should not rely on it's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pageviews in control: 345543\n",
      "Number of pageviews in experiment: 344660\n"
     ]
    }
   ],
   "source": [
    "pageviews_cont = control['Pageviews'].sum()\n",
    "pageviews_exp = experiment['Pageviews'].sum()\n",
    "pageviews_total = pageviews_cont + pageviews_exp\n",
    "print (\"Number of pageviews in control:\", pageviews_cont)\n",
    "print (\"Number of pageviews in experiment:\", pageviews_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look like pretty close numbers. Now, let's make sure this difference in amounts is not significant and is random and even like we expected. We can model this diversion in the following way:\n",
    "We expect the amount of pageviews in the control group to be about a half (50%) of the total pageviews in both groups, so we can define a random variable with an easy to use distribution.\n",
    "A binomial random variable will be the number of successes we can expect to get out of N experiments, given the probability of a single success. \n",
    "\n",
    "So, if we consider being assigned to a group (control, for example) a success with probability 0.5 (random!), the number of samples which get assigned to the group is the value of our random binomial variable!\n",
    "\n",
    "This get's easier thanks to the central limit theorem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p = 0.5\n",
    "alpha = 0.05\n",
    "p_hat = round(pageviews_cont/(pageviews_total),4)\n",
    "sd = mt.sqrt(p*(1-p)/(pageviews_total))\n",
    "ME = round(get_z_score(1-(alpha/2))*sd,4)\n",
    "print(\"The confidence interval is between\",p-ME,\"and\",p+ME,\"; Is\",p_hat,\"inside this range?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of the confidence interval is between 0.4988 and 0.5012, and the sample value is 0.5006\n",
    "\n",
    "As can be seen\n",
    "\n",
    "The sample ratio of the control group is 0.5006 within the confidence interval, so the pv (page uv) indicator is passed the test, and there is no significant difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is between 0.4959 and 0.5041 ; Is 0.5005 inside this range?\n"
     ]
    }
   ],
   "source": [
    "clicks_cont=control['Clicks'].sum()\n",
    "clicks_exp=experiment['Clicks'].sum()\n",
    "clicks_total=clicks_cont+clicks_exp\n",
    "\n",
    "p_hat = round(clicks_cont/clicks_total,4)\n",
    "sd = mt.sqrt(p*(1-p)/clicks_total)\n",
    "ME = round(get_z_score(1-(alpha/2))*sd,4)\n",
    "print(\"The confidence interval is between\",p-ME,\"and\",p+ME,\"; Is\",p_hat,\"inside this range?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The range of the error confidence interval is between 0.4959 and 0.5041, and the sample value is 0.5005.\n",
    "\n",
    "We have another pass! Great, so far it still seems all is well with our experiment results. Now, for the final metric which is a probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Examining the effect size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is looking at the changes between the control and experiment groups with regard to our evaluation metrics to make sure the difference is there, that it is statistically significant and most importantly practically significant (the difference is \"big\" enough to make the experimented change beneficial to the company).\n",
    "\n",
    "Now, all that is left is to measure for each evaluation metric, the difference between the values from both groups. Then, we compute the confidence interval for that difference and test whether or not this confidence interval is both statistically and practically significant.\n",
    "\n",
    "- Gross Conversion: a metric is statistically significant if the confidence interval does not include 0 (that is, you can be confident there was a change), and it is practically significant if the confidence interval does not include the practical significance boundary (that is, you can be confident there is a change that matters to the business.)\n",
    "\n",
    "\n",
    "Important: The given spreadsheet lists pageviews and clicks for 39 days, while it only lists enrollments and payments for 23 days. So, when working with enrollments and payments we should notice using only the corresponding pageviews and clicks, and not all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the effective clicks of the experimental group and the control group\n",
    "clicks_cont = control[\"Clicks\"].loc[control[\"Enrollments\"].notnull()].sum()\n",
    "clicks_exp = experiment[\"Clicks\"].loc[experiment[\"Enrollments\"].notnull()].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gross Conversion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The change due to the experiment is -2.06 %\n",
      "Confidence Interval: [ -0.0292 , -0.012 ]\n",
      "The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if -0.01 is not in the CI as well.\n"
     ]
    }
   ],
   "source": [
    "#Gross Conversion - number of enrollments divided by number of clicks\n",
    "enrollments_cont=control[\"Enrollments\"].sum()\n",
    "enrollments_exp=experiment[\"Enrollments\"].sum()\n",
    "\n",
    "GC_cont=enrollments_cont/clicks_cont\n",
    "GC_exp=enrollments_exp/clicks_exp\n",
    "GC_pooled=(enrollments_cont+enrollments_exp)/(clicks_cont+clicks_exp)\n",
    "GC_sd_pooled=mt.sqrt(GC_pooled*(1-GC_pooled)*(1/clicks_cont+1/clicks_exp))\n",
    "GC_ME=round(get_z_score(1-alpha/2)*GC_sd_pooled,4)\n",
    "GC_diff=round(GC_exp-GC_cont,4)\n",
    "print(\"The change due to the experiment is\",GC_diff*100,\"%\")\n",
    "print(\"Confidence Interval: [\",GC_diff-GC_ME,\",\",GC_diff+GC_ME,\"]\")\n",
    "print (\"The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if\",-GC[\"d_min\"],\"is not in the CI as well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this result there was a change due to the experiment, that change was both statistically and practically significant. We have a negative change of 2.06%, when we were willing to accept any change greater than 1%. This means the Gross Conversion rate of the experiment group (the one exposed to the change, i.e. asked how many hours they can devote to studying) has decreased as expected by 2% and this change was significant. This means less people enrolled in the Free Trial after due to the pop-up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Net Conversion: the hypothesis is the same as before just with net conversion instead of gross. At this point we expect the fraction of payers (out of the clicks) to decrease as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The change due to the experiment is -0.49 %\n",
      "Confidence Interval: [ -0.0116 , 0.0018000000000000004 ]\n",
      "The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if 0.0075 is not in the CI as well.\n"
     ]
    }
   ],
   "source": [
    "#Net Conversion - number of payments divided by number of clicks\n",
    "payments_cont=control[\"Payments\"].sum()\n",
    "payments_exp=experiment[\"Payments\"].sum()\n",
    "\n",
    "NC_cont = payments_cont/clicks_cont\n",
    "NC_exp = payments_exp/clicks_exp\n",
    "NC_pooled = (payments_cont+payments_exp)/(clicks_cont+clicks_exp)\n",
    "NC_sd_pooled = mt.sqrt(NC_pooled*(1-NC_pooled)*(1/clicks_cont+1/clicks_exp))\n",
    "NC_ME = round(get_z_score(1-alpha/2)*NC_sd_pooled,4)\n",
    "NC_diff = round(NC_exp-NC_cont,4)\n",
    "print(\"The change due to the experiment is\", NC_diff*100,\"%\")\n",
    "print(\"Confidence Interval: [\",NC_diff-NC_ME, \",\", NC_diff+NC_ME, \"]\")\n",
    "print (\"The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if\", 0.0075, \"is not in the CI as well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicator changes due to strategy: -0.49%\n",
    "Confidence interval: [-0.0116, 0.0018]\n",
    "\n",
    "The confidence interval of the error does not include 0, and the D_min of NC is 0.75%, so the index difference is statistically significant, but it is not significant in practical significance, that is, the benefit is not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Double check with sign tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a sign test we get another angle at analyzing the results we got - we check if the trend of change we observed (increase or decrease) was evident in the daily data. We are goint to compute the metric's value per day and then count on how many days the metric was lower in the experiment group and this will be the number of succssesses for our binomial variable. Once this is defined we can look at the proportion of days of success out of all the available days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date_cont           37\n",
       "Pageviews_cont      37\n",
       "Clicks_cont         37\n",
       "Enrollments_cont    23\n",
       "Payments_cont       23\n",
       "Date_exp            37\n",
       "Pageviews_exp       37\n",
       "Clicks_exp          37\n",
       "Enrollments_exp     23\n",
       "Payments_exp        23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's first create the dataset we need for this:\n",
    "# Start by merging the two datasets\n",
    "full = control.join(other=experiment,how=\"inner\",lsuffix=\"_cont\",rsuffix=\"_exp\")\n",
    "# Let's look at what we got\n",
    "full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date_cont           23\n",
       "Pageviews_cont      23\n",
       "Clicks_cont         23\n",
       "Enrollments_cont    23\n",
       "Payments_cont       23\n",
       "Date_exp            23\n",
       "Pageviews_exp       23\n",
       "Clicks_exp          23\n",
       "Enrollments_exp     23\n",
       "Payments_exp        23\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we only need the complete data records\n",
    "full = full.loc[full[\"Enrollments_cont\"].notnull()]\n",
    "full.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_cont</th>\n",
       "      <th>Pageviews_cont</th>\n",
       "      <th>Clicks_cont</th>\n",
       "      <th>Enrollments_cont</th>\n",
       "      <th>Payments_cont</th>\n",
       "      <th>Date_exp</th>\n",
       "      <th>Pageviews_exp</th>\n",
       "      <th>Clicks_exp</th>\n",
       "      <th>Enrollments_exp</th>\n",
       "      <th>Payments_exp</th>\n",
       "      <th>GC</th>\n",
       "      <th>NC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7723</td>\n",
       "      <td>687</td>\n",
       "      <td>134.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Sat, Oct 11</td>\n",
       "      <td>7716</td>\n",
       "      <td>686</td>\n",
       "      <td>105.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9102</td>\n",
       "      <td>779</td>\n",
       "      <td>147.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Sun, Oct 12</td>\n",
       "      <td>9288</td>\n",
       "      <td>785</td>\n",
       "      <td>116.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10511</td>\n",
       "      <td>909</td>\n",
       "      <td>167.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Mon, Oct 13</td>\n",
       "      <td>10480</td>\n",
       "      <td>884</td>\n",
       "      <td>145.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9871</td>\n",
       "      <td>836</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>Tue, Oct 14</td>\n",
       "      <td>9867</td>\n",
       "      <td>827</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>10014</td>\n",
       "      <td>837</td>\n",
       "      <td>163.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Wed, Oct 15</td>\n",
       "      <td>9793</td>\n",
       "      <td>832</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Date_cont  Pageviews_cont  Clicks_cont  Enrollments_cont  Payments_cont  \\\n",
       "0  Sat, Oct 11            7723          687             134.0           70.0   \n",
       "1  Sun, Oct 12            9102          779             147.0           70.0   \n",
       "2  Mon, Oct 13           10511          909             167.0           95.0   \n",
       "3  Tue, Oct 14            9871          836             156.0          105.0   \n",
       "4  Wed, Oct 15           10014          837             163.0           64.0   \n",
       "\n",
       "      Date_exp  Pageviews_exp  Clicks_exp  Enrollments_exp  Payments_exp  GC  \\\n",
       "0  Sat, Oct 11           7716         686            105.0          34.0   0   \n",
       "1  Sun, Oct 12           9288         785            116.0          91.0   0   \n",
       "2  Mon, Oct 13          10480         884            145.0          79.0   0   \n",
       "3  Tue, Oct 14           9867         827            138.0          92.0   0   \n",
       "4  Wed, Oct 15           9793         832            140.0          94.0   0   \n",
       "\n",
       "   NC  \n",
       "0   0  \n",
       "1   1  \n",
       "2   0  \n",
       "3   0  \n",
       "4   1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, derive a new column for each metric, so we have it's daily values\n",
    "# We need a 1 if the experiment value is greater than the control value=\n",
    "x = full['Enrollments_cont']/full['Clicks_cont']\n",
    "y = full['Enrollments_exp']/full['Clicks_exp']\n",
    "full['GC'] = np.where(x<y,1,0)\n",
    "# The same now for net conversion\n",
    "z = full['Payments_cont']/full['Clicks_cont']\n",
    "w = full['Payments_exp']/full['Clicks_exp']\n",
    "full['NC'] = np.where(z<w,1,0)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of cases for GC: 4 \n",
      " No. of cases for NC: 10 \n",
      " No. of total cases 23\n"
     ]
    }
   ],
   "source": [
    "GC_x = full.GC[full[\"GC\"]==1].count()\n",
    "NC_x = full.NC[full[\"NC\"]==1].count()\n",
    "n = full.NC.count()\n",
    "print(\"No. of cases for GC:\",GC_x,'\\n',\n",
    "      \"No. of cases for NC:\",NC_x,'\\n',\n",
    "      \"No. of total cases\",n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Building a Sign Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can forget all about this part and just use an online sign test calculator, but I still want to implement the calculations behind it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First a function for calculating probability of x=number of successes\n",
    "def get_prob(x,n):\n",
    "    p=round(mt.factorial(n)/(mt.factorial(x)*mt.factorial(n-x))*0.5**x*0.5**(n-x),4)\n",
    "    return p\n",
    "# Next a function to compute the pvalue from probabilities of maximum x\n",
    "def get_2side_pvalue(x,n):\n",
    "    p = 0\n",
    "    for i in range(0,x+1):\n",
    "        p = p+get_prob(i,n)\n",
    "    return 2*p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to conduct the sign test itself: we will calculate the p-value for each metric, using the counts GC_x,NC_x and n and the function get_2side_pvalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC Change is significant if 0.0026000000000000003 is smaller than 0.05\n",
      "NC Change is significant if 0.6774 is smaller than 0.05\n"
     ]
    }
   ],
   "source": [
    "print (\"GC Change is significant if\",get_2side_pvalue(GC_x,n),\"is smaller than 0.05\")\n",
    "print (\"NC Change is significant if\",get_2side_pvalue(NC_x,n),\"is smaller than 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same conclusions as we got from our effect size calculation: the change in Gross Conversion was indeed significant, while the change in Net Conversion was not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, once we have seen that the actual underlying goal we had was not reached (increase fraction of paying users by asking them in advance if they have the time to invest in the course), we can only recommend to not continue with change. It may have caused a change in Gross conversion, but it didn't for net conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda97b91eb2f02e45e79fee5602947ff515"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
